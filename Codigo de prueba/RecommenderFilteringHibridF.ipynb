{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\isaac\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\isaac\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATING_COLS = ['user', 'rating', 'ID', 'comment']\n",
    "GAME_INFO_COLS = ['id', 'primary', 'yearpublished', 'minplayers', 'maxplayers',\n",
    "                  'playingtime', 'boardgamecategory', 'boardgamemechanic',\n",
    "                  'boardgamefamily', 'boardgamedesigner', 'boardgamepublisher',\n",
    "                  'usersrated', 'average', 'Board Game Rank', 'numcomments',\n",
    "                  'averageweight']\n",
    "\n",
    "# Rutas de los archivos CSV (ajustar según la ubicación de tus archivos)\n",
    "RATINGS_CSV = \"../data/bgg-26m-reviews.csv\"         # Archivo con ratings y comentarios\n",
    "GAMES_CSV = \"../data/games_detailed_info.csv\"         # Archivo con información de juegos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings(ratings_file=RATINGS_CSV):\n",
    "    \"\"\"\n",
    "    Carga el CSV de ratings utilizando las columnas definidas y renombra 'ID' a 'game_id'.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(ratings_file):\n",
    "        raise FileNotFoundError(f\"El archivo {ratings_file} no se encontró.\")\n",
    "    ratings_df = pd.read_csv(ratings_file, usecols=RATING_COLS, low_memory=False)\n",
    "    ratings_df.rename(columns={'ID': 'game_id'}, inplace=True)\n",
    "    return ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_game_info(games_file=GAMES_CSV):\n",
    "    \"\"\"\n",
    "    Carga el CSV de información de juegos utilizando las columnas definidas y renombra 'id' a 'game_id'.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(games_file):\n",
    "        raise FileNotFoundError(f\"El archivo {games_file} no se encontró.\")\n",
    "    games_df = pd.read_csv(games_file, usecols=lambda col: col in GAME_INFO_COLS, low_memory=False)\n",
    "    if 'id' in games_df.columns:\n",
    "        games_df.rename(columns={'id': 'game_id'}, inplace=True)\n",
    "    return games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(df, columns_to_check):\n",
    "    \"\"\"\n",
    "    Elimina duplicados y filas con valores nulos en las columnas especificadas.\n",
    "    \"\"\"\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    df_cleaned = df_cleaned.dropna(subset=columns_to_check)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory_usage(df):\n",
    "    \"\"\"\n",
    "    Convierte las columnas de tipo object a string para optimizar el uso de memoria.\n",
    "    \"\"\"\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_text(games_df):\n",
    "    \"\"\"\n",
    "    Combina las columnas textuales relevantes del dataframe de juegos para formar\n",
    "    una única columna 'combined_text' que servirá para el análisis basado en contenido.\n",
    "    Se utilizan: 'primary', 'boardgamecategory', 'boardgamemechanic',\n",
    "    'boardgamefamily', 'boardgamedesigner' y 'boardgamepublisher'.\n",
    "    \"\"\"\n",
    "    text_columns = ['primary', 'boardgamecategory', 'boardgamemechanic', \n",
    "                    'boardgamefamily', 'boardgamedesigner', 'boardgamepublisher']\n",
    "    \n",
    "    # Rellenar con cadena vacía si la columna no existe o tiene valores nulos\n",
    "    for col in text_columns:\n",
    "        if col in games_df.columns:\n",
    "            games_df[col] = games_df[col].fillna(\"\").astype(str)\n",
    "        else:\n",
    "            games_df[col] = \"\"\n",
    "    \n",
    "    # Combinar las columnas en una sola cadena\n",
    "    games_df['combined_text'] = games_df[text_columns].apply(lambda row: \" \".join(row.values.astype(str)), axis=1)\n",
    "    return games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, stemmer, stop_words):\n",
    "    \"\"\"\n",
    "    Preprocesa el texto: lo convierte a minúsculas, elimina puntuación,\n",
    "    tokeniza, elimina stopwords y aplica stemming.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_text_preprocessing(df, source_column, target_column):\n",
    "    \"\"\"\n",
    "    Aplica el preprocesamiento de texto a la columna 'source_column' y almacena el resultado en 'target_column'.\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    df[target_column] = df[source_column].apply(lambda x: preprocess_text(x, stemmer, stop_words))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_ratings(ratings_df):\n",
    "    \"\"\"\n",
    "    Agrupa los ratings por 'game_id' calculando el promedio y la cantidad de ratings.\n",
    "    Además, concatena todos los comentarios en una única cadena por juego.\n",
    "    \"\"\"\n",
    "    aggregated = ratings_df.groupby('game_id').agg(\n",
    "        average_rating=pd.NamedAgg(column='rating', aggfunc='mean'),\n",
    "        num_ratings=pd.NamedAgg(column='rating', aggfunc='count'),\n",
    "        aggregated_comments=pd.NamedAgg(column='comment', aggfunc=lambda x: \" \".join(x.astype(str)))\n",
    "    ).reset_index()\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(games_df, aggregated_ratings):\n",
    "    \"\"\"\n",
    "    Une el dataframe de juegos con el dataframe de ratings agregados utilizando 'game_id'.\n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(games_df, aggregated_ratings, on='game_id', how='left')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPreprocesamiento completado. Datos guardados en \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m games_df = apply_text_preprocessing(games_df, \u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mprocessed_game_text\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 7. Preprocesar los comentarios agregados\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m aggregated_ratings = \u001b[43mapply_text_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregated_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maggregated_comments\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprocessed_comments\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 8. Unir datasets: información de juegos con ratings agregados\u001b[39;00m\n\u001b[32m     27\u001b[39m merged_df = merge_datasets(games_df, aggregated_ratings)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mapply_text_preprocessing\u001b[39m\u001b[34m(df, source_column, target_column)\u001b[39m\n\u001b[32m      5\u001b[39m stemmer = SnowballStemmer(\u001b[33m'\u001b[39m\u001b[33mspanish\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m stop_words = \u001b[38;5;28mset\u001b[39m(stopwords.words(\u001b[33m'\u001b[39m\u001b[33mspanish\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df[target_column] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43msource_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstemmer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_words\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\base.py:919\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    916\u001b[39m arr = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\base.py:2322\u001b[39m, in \u001b[36mExtensionArray.map\u001b[39m\u001b[34m(self, mapper, na_action)\u001b[39m\n\u001b[32m   2302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapper, na_action=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2303\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2304\u001b[39m \u001b[33;03m    Map values using an input mapping or function.\u001b[39;00m\n\u001b[32m   2305\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2320\u001b[39m \u001b[33;03m        a MultiIndex will be returned.\u001b[39;00m\n\u001b[32m   2321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mapply_text_preprocessing.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      5\u001b[39m stemmer = SnowballStemmer(\u001b[33m'\u001b[39m\u001b[33mspanish\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m stop_words = \u001b[38;5;28mset\u001b[39m(stopwords.words(\u001b[33m'\u001b[39m\u001b[33mspanish\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df[target_column] = df[source_column].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstemmer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_words\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mpreprocess_text\u001b[39m\u001b[34m(text, stemmer, stop_words)\u001b[39m\n\u001b[32m      7\u001b[39m text = text.translate(\u001b[38;5;28mstr\u001b[39m.maketrans(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, string.punctuation))\n\u001b[32m      8\u001b[39m tokens = nltk.word_tokenize(text)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m filtered_tokens = \u001b[43m[\u001b[49m\u001b[43mstemmer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstop_words\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(filtered_tokens)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      7\u001b[39m text = text.translate(\u001b[38;5;28mstr\u001b[39m.maketrans(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, string.punctuation))\n\u001b[32m      8\u001b[39m tokens = nltk.word_tokenize(text)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m filtered_tokens = [\u001b[43mstemmer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(filtered_tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\stem\\snowball.py:5695\u001b[39m, in \u001b[36mSpanishStemmer.stem\u001b[39m\u001b[34m(self, word)\u001b[39m\n\u001b[32m   5693\u001b[39m rv = rv[: -\u001b[38;5;28mlen\u001b[39m(suffix)]\n\u001b[32m   5694\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mes\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\xE9\u001b[39;00m\u001b[33mis\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33memos\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m5695\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m   5696\u001b[39m         word = word[:-\u001b[32m1\u001b[39m]\n\u001b[32m   5698\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rv.endswith(\u001b[33m\"\u001b[39m\u001b[33mgu\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1. Cargar datasets\n",
    "    ratings_df = load_ratings()\n",
    "    games_df = load_game_info()\n",
    "    \n",
    "    # 2. Limpiar datos: eliminar duplicados y registros nulos en columnas esenciales\n",
    "    ratings_df = clean_data(ratings_df, ['rating', 'user', 'comment'])\n",
    "    # Añadir eliminación de valores nulos para todos las columnas\n",
    "    games_df = clean_data(games_df, ['primary'])\n",
    "    \n",
    "    # 3. Optimizar uso de memoria\n",
    "    ratings_df = optimize_memory_usage(ratings_df)\n",
    "    games_df = optimize_memory_usage(games_df)\n",
    "    \n",
    "    # 4. Agregar ratings: calcular promedio, cantidad y concatenar comentarios por juego\n",
    "    aggregated_ratings = aggregate_ratings(ratings_df)\n",
    "    \n",
    "    # 5. Crear columna de texto combinada en games_df a partir de las columnas textuales relevantes\n",
    "    games_df = create_combined_text(games_df)\n",
    "    \n",
    "    # 6. Preprocesar el texto combinado de los juegos\n",
    "    games_df = apply_text_preprocessing(games_df, 'combined_text', 'processed_game_text')\n",
    "    \n",
    "    # 7. Preprocesar los comentarios agregados\n",
    "    aggregated_ratings = apply_text_preprocessing(aggregated_ratings, 'aggregated_comments', 'processed_comments')\n",
    "    \n",
    "    # 8. Unir datasets: información de juegos con ratings agregados\n",
    "    merged_df = merge_datasets(games_df, aggregated_ratings)\n",
    "    \n",
    "    # 9. Crear una columna final que combine el texto preprocesado de juegos y comentarios (si existen)\n",
    "    merged_df['final_text'] = merged_df['processed_game_text'] + \" \" + merged_df['processed_comments'].fillna(\"\")\n",
    "    \n",
    "    # 10. Guardar el DataFrame final preprocesado en un nuevo archivo CSV\n",
    "    output_file = \"preprocessed_boardgame_data.csv\"\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Preprocesamiento completado. Datos guardados en '{output_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
